{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31680e0-9037-40e9-a635-08c2de8ed9a4",
   "metadata": {},
   "source": [
    "# RoBERTa Fine Tunning For Helpfulness Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a039072-ec9b-428f-b95c-84dce51ac2ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347acc6-4841-4897-96ba-01c43a6b2f26",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536151d0-6f17-48be-ada0-cb8b528008a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d879199-46bc-42de-8a44-1b307d49ba5e",
   "metadata": {},
   "source": [
    "## Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94b9715-65b5-43e9-bead-f3818128c473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657855651a6d2c7052a63c2e</td>\n",
       "      <td>The selection here is okay if you're making ga...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a64d48</td>\n",
       "      <td>Now THIS is a restaurant.  Small, tidy, excell...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63de3</td>\n",
       "      <td>In the last five minutes I had two men knock o...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657859921a6d2c7052a6529f</td>\n",
       "      <td>I love Potbelly's.  I've eaten there several t...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657855641a6d2c7052a63332</td>\n",
       "      <td>This is the best thai cuisine around, the curr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995</td>\n",
       "      <td>657859921a6d2c7052a64d6e</td>\n",
       "      <td>Service was good and friendly.  Food was good ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996</td>\n",
       "      <td>657855651a6d2c7052a6440c</td>\n",
       "      <td>This place is a complete joke. I bought 4 tire...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997</td>\n",
       "      <td>657855651a6d2c7052a64353</td>\n",
       "      <td>I waited a week to post my review of White Dog...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998</td>\n",
       "      <td>657855641a6d2c7052a633cd</td>\n",
       "      <td>We had a Groupon for Euphoria, so my husband a...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999</td>\n",
       "      <td>657859931a6d2c7052a659e9</td>\n",
       "      <td>I love this place. It's great for after work h...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657855651a6d2c7052a63c2e   \n",
       "1              1  657859921a6d2c7052a64d48   \n",
       "2              2  657855651a6d2c7052a63de3   \n",
       "3              3  657859921a6d2c7052a6529f   \n",
       "4              4  657855641a6d2c7052a63332   \n",
       "...          ...                       ...   \n",
       "7995        7995  657859921a6d2c7052a64d6e   \n",
       "7996        7996  657855651a6d2c7052a6440c   \n",
       "7997        7997  657855651a6d2c7052a64353   \n",
       "7998        7998  657855641a6d2c7052a633cd   \n",
       "7999        7999  657859931a6d2c7052a659e9   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     The selection here is okay if you're making ga...    helpful        1   \n",
       "1     Now THIS is a restaurant.  Small, tidy, excell...  unhelpful        0   \n",
       "2     In the last five minutes I had two men knock o...    helpful        1   \n",
       "3     I love Potbelly's.  I've eaten there several t...  unhelpful        0   \n",
       "4     This is the best thai cuisine around, the curr...    helpful        1   \n",
       "...                                                 ...        ...      ...   \n",
       "7995  Service was good and friendly.  Food was good ...  unhelpful        0   \n",
       "7996  This place is a complete joke. I bought 4 tire...    helpful        1   \n",
       "7997  I waited a week to post my review of White Dog...    helpful        1   \n",
       "7998  We had a Groupon for Euphoria, so my husband a...    helpful        1   \n",
       "7999  I love this place. It's great for after work h...  unhelpful        0   \n",
       "\n",
       "      unhelpful  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "7995          1  \n",
       "7996          0  \n",
       "7997          0  \n",
       "7998          0  \n",
       "7999          1  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fcfee4-029c-4d24-be29-66a95fe17f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "helpful      4000\n",
       "unhelpful    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d1977e-0da4-4760-af37-68c2e57603a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657859921a6d2c7052a64801</td>\n",
       "      <td>I was out in St. Louis on a business trip and ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a647aa</td>\n",
       "      <td>Worst omelet I have ever eaten. With the upcha...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63749</td>\n",
       "      <td>I love this place! It is my favorite go to pla...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657855651a6d2c7052a6408a</td>\n",
       "      <td>Came to Tamarind for lunch on Sunday afternoon...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657859921a6d2c7052a6554d</td>\n",
       "      <td>Easter Sunday, over crowded at 6:00 PM, staff ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>657859921a6d2c7052a65259</td>\n",
       "      <td>Love this dealership. Bought my CRV there a fe...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>657855651a6d2c7052a63ce4</td>\n",
       "      <td>We stopped at Tako due to the positive reviews...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>657855651a6d2c7052a63d89</td>\n",
       "      <td>I had a quick get together with a couple of fr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>657859921a6d2c7052a64b23</td>\n",
       "      <td>After a long week, a girl friend and I decided...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>657855651a6d2c7052a636bc</td>\n",
       "      <td>So I placed my order boneless wings, she also ...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657859921a6d2c7052a64801   \n",
       "1              1  657859921a6d2c7052a647aa   \n",
       "2              2  657855651a6d2c7052a63749   \n",
       "3              3  657855651a6d2c7052a6408a   \n",
       "4              4  657859921a6d2c7052a6554d   \n",
       "...          ...                       ...   \n",
       "1995        1995  657859921a6d2c7052a65259   \n",
       "1996        1996  657855651a6d2c7052a63ce4   \n",
       "1997        1997  657855651a6d2c7052a63d89   \n",
       "1998        1998  657859921a6d2c7052a64b23   \n",
       "1999        1999  657855651a6d2c7052a636bc   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     I was out in St. Louis on a business trip and ...  unhelpful        0   \n",
       "1     Worst omelet I have ever eaten. With the upcha...  unhelpful        0   \n",
       "2     I love this place! It is my favorite go to pla...    helpful        1   \n",
       "3     Came to Tamarind for lunch on Sunday afternoon...    helpful        1   \n",
       "4     Easter Sunday, over crowded at 6:00 PM, staff ...  unhelpful        0   \n",
       "...                                                 ...        ...      ...   \n",
       "1995  Love this dealership. Bought my CRV there a fe...  unhelpful        0   \n",
       "1996  We stopped at Tako due to the positive reviews...    helpful        1   \n",
       "1997  I had a quick get together with a couple of fr...    helpful        1   \n",
       "1998  After a long week, a girl friend and I decided...  unhelpful        0   \n",
       "1999  So I placed my order boneless wings, she also ...    helpful        1   \n",
       "\n",
       "      unhelpful  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1995          1  \n",
       "1996          0  \n",
       "1997          0  \n",
       "1998          1  \n",
       "1999          0  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0c0bff-2328-477e-87a0-71fc29ca48fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "unhelpful    1000\n",
       "helpful      1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eede441-316e-400c-a059-81e93cdbf922",
   "metadata": {},
   "source": [
    "### Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1400456c-9bf4-4920-b8eb-e5c1d3eb5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, newline=True, quote=True, bullet_point=True, \n",
    "          link=True, strikethrough=True, spoiler=True,\n",
    "          code=True, superscript=True, table=True, heading=True):\n",
    "    \n",
    "    text = re.sub(\"[^a-zA-Z]\",  \" \", str(text))\n",
    "    \n",
    "    if newline:\n",
    "        text = re.sub(r'\\n+', ' ', text)\n",
    "        text = text.strip()\n",
    "        text = re.sub(r'\\s\\s+', ' ', text)\n",
    "\n",
    "    if quote:\n",
    "        text = re.sub(r'\\\"?\\\\?&?gt;?', '', text)\n",
    "\n",
    "    if bullet_point:\n",
    "        text = re.sub(r'\\*', '', text)\n",
    "        text = re.sub('&amp;#x200B;', '', text)\n",
    "\n",
    "    if link:\n",
    "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "\n",
    "    if strikethrough:\n",
    "        text = re.sub('~', '', text)\n",
    "\n",
    "    if spoiler:\n",
    "        text = re.sub('&lt;', '', text)\n",
    "        text = re.sub(r'!(.*?)!', r'\\1', text)\n",
    "\n",
    "    if code:\n",
    "        text = re.sub('`', '', text)\n",
    "\n",
    "    if superscript:\n",
    "        text = re.sub(r'\\^\\((.*?)\\)', r'\\1', text)\n",
    "\n",
    "    if table:\n",
    "        text = re.sub(r'\\|', ' ', text)\n",
    "        text = re.sub(':-', '', text)\n",
    "\n",
    "    if heading:\n",
    "        text = re.sub('#', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea179ca7-bc10-410f-adf2-a103d1a96828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657855651a6d2c7052a63c2e</td>\n",
       "      <td>The selection here is okay if you re making ga...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a64d48</td>\n",
       "      <td>Now THIS is a restaurant Small tidy excellent ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63de3</td>\n",
       "      <td>In the last five minutes I had two men knock o...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657859921a6d2c7052a6529f</td>\n",
       "      <td>I love Potbelly s I ve eaten there several tim...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657855641a6d2c7052a63332</td>\n",
       "      <td>This is the best thai cuisine around the curry...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995</td>\n",
       "      <td>657859921a6d2c7052a64d6e</td>\n",
       "      <td>Service was good and friendly Food was good wi...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996</td>\n",
       "      <td>657855651a6d2c7052a6440c</td>\n",
       "      <td>This place is a complete joke I bought tires o...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997</td>\n",
       "      <td>657855651a6d2c7052a64353</td>\n",
       "      <td>I waited a week to post my review of White Dog...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998</td>\n",
       "      <td>657855641a6d2c7052a633cd</td>\n",
       "      <td>We had a Groupon for Euphoria so my husband an...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999</td>\n",
       "      <td>657859931a6d2c7052a659e9</td>\n",
       "      <td>I love this place It s great for after work ha...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657855651a6d2c7052a63c2e   \n",
       "1              1  657859921a6d2c7052a64d48   \n",
       "2              2  657855651a6d2c7052a63de3   \n",
       "3              3  657859921a6d2c7052a6529f   \n",
       "4              4  657855641a6d2c7052a63332   \n",
       "...          ...                       ...   \n",
       "7995        7995  657859921a6d2c7052a64d6e   \n",
       "7996        7996  657855651a6d2c7052a6440c   \n",
       "7997        7997  657855651a6d2c7052a64353   \n",
       "7998        7998  657855641a6d2c7052a633cd   \n",
       "7999        7999  657859931a6d2c7052a659e9   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     The selection here is okay if you re making ga...    helpful        1   \n",
       "1     Now THIS is a restaurant Small tidy excellent ...  unhelpful        0   \n",
       "2     In the last five minutes I had two men knock o...    helpful        1   \n",
       "3     I love Potbelly s I ve eaten there several tim...  unhelpful        0   \n",
       "4     This is the best thai cuisine around the curry...    helpful        1   \n",
       "...                                                 ...        ...      ...   \n",
       "7995  Service was good and friendly Food was good wi...  unhelpful        0   \n",
       "7996  This place is a complete joke I bought tires o...    helpful        1   \n",
       "7997  I waited a week to post my review of White Dog...    helpful        1   \n",
       "7998  We had a Groupon for Euphoria so my husband an...    helpful        1   \n",
       "7999  I love this place It s great for after work ha...  unhelpful        0   \n",
       "\n",
       "      unhelpful  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "7995          1  \n",
       "7996          0  \n",
       "7997          0  \n",
       "7998          0  \n",
       "7999          1  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'] = train_df['text'].apply(lambda x: clean(x))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f9efa6-ae02-4e66-aa92-0a64f72dc08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657859921a6d2c7052a64801</td>\n",
       "      <td>I was out in St Louis on a business trip and w...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a647aa</td>\n",
       "      <td>Worst omelet I have ever eaten With the upchar...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63749</td>\n",
       "      <td>I love this place It is my favorite go to plac...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657855651a6d2c7052a6408a</td>\n",
       "      <td>Came to Tamarind for lunch on Sunday afternoon...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657859921a6d2c7052a6554d</td>\n",
       "      <td>Easter Sunday over crowded at PM staff lacked ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>657859921a6d2c7052a65259</td>\n",
       "      <td>Love this dealership Bought my CRV there a few...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>657855651a6d2c7052a63ce4</td>\n",
       "      <td>We stopped at Tako due to the positive reviews...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>657855651a6d2c7052a63d89</td>\n",
       "      <td>I had a quick get together with a couple of fr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>657859921a6d2c7052a64b23</td>\n",
       "      <td>After a long week a girl friend and I decided ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>657855651a6d2c7052a636bc</td>\n",
       "      <td>So I placed my order boneless wings she also r...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657859921a6d2c7052a64801   \n",
       "1              1  657859921a6d2c7052a647aa   \n",
       "2              2  657855651a6d2c7052a63749   \n",
       "3              3  657855651a6d2c7052a6408a   \n",
       "4              4  657859921a6d2c7052a6554d   \n",
       "...          ...                       ...   \n",
       "1995        1995  657859921a6d2c7052a65259   \n",
       "1996        1996  657855651a6d2c7052a63ce4   \n",
       "1997        1997  657855651a6d2c7052a63d89   \n",
       "1998        1998  657859921a6d2c7052a64b23   \n",
       "1999        1999  657855651a6d2c7052a636bc   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     I was out in St Louis on a business trip and w...  unhelpful        0   \n",
       "1     Worst omelet I have ever eaten With the upchar...  unhelpful        0   \n",
       "2     I love this place It is my favorite go to plac...    helpful        1   \n",
       "3     Came to Tamarind for lunch on Sunday afternoon...    helpful        1   \n",
       "4     Easter Sunday over crowded at PM staff lacked ...  unhelpful        0   \n",
       "...                                                 ...        ...      ...   \n",
       "1995  Love this dealership Bought my CRV there a few...  unhelpful        0   \n",
       "1996  We stopped at Tako due to the positive reviews...    helpful        1   \n",
       "1997  I had a quick get together with a couple of fr...    helpful        1   \n",
       "1998  After a long week a girl friend and I decided ...  unhelpful        0   \n",
       "1999  So I placed my order boneless wings she also r...    helpful        1   \n",
       "\n",
       "      unhelpful  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1995          1  \n",
       "1996          0  \n",
       "1997          0  \n",
       "1998          1  \n",
       "1999          0  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'] = test_df['text'].apply(lambda x: clean(x))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b5cd1-d7b0-4a79-a056-0237c48ce6ab",
   "metadata": {},
   "source": [
    "## Build PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b5177a-856a-48ca-9802-ae2218b21b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063075d7-b8a5-4d04-a348-f40106ffffb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, tokenizer, attributes, max_token_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        text = item.text\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        tokens = self.tokenizer.encode_plus(text,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_tensors=\"pt\",\n",
    "                                            truncation=True,\n",
    "                                            max_length=self.max_token_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            return_attention_mask=True)\n",
    "        return {\n",
    "            \"input_ids\": tokens.input_ids.flatten(),\n",
    "            \"attention_mask\": tokens.attention_mask.flatten(),\n",
    "            \"labels\": attributes\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82f2cd-b3b0-4e2a-b23f-4cf55ed3ad16",
   "metadata": {},
   "source": [
    "## Create Train And Test PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c1770f-27c2-4ca9-81ac-b223fd2f5d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\"helpful\", \"unhelpful\"]\n",
    "model_name = \"roberta-base\"\n",
    "max_token_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "hfs_ds_train = Helpfulness_Dataset(train_df, tokenizer, attributes, max_token_length)\n",
    "hfs_ds_val = Helpfulness_Dataset(test_df, tokenizer, attributes, max_token_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356846f-49e2-47d8-94d0-cf3b8516f661",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5b7e4-455b-4be3-8acd-2a77f9f219e8",
   "metadata": {},
   "source": [
    "### Helpful Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8685dd7c-b51d-4512-bd5e-445b6e69b4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The selection here is okay if you re making garments quilting even rag is a no go ever Fleece selection and price is great and one of the reasons to go here Warm and natural batting is more expensive than Hancock or anywhere else except high end quilt shops Price is okay on fabric for garments and there s a nice selection of silk rayon syn but the quality of some fabrics reflects the low everyday price My opinion is that these are nd and rd cut fabrics not top quality If you use a coupon or go for a sale at Hancock you can get better quality fabric at close to the same price Plus their notions are about non existant just try to match thread to fabric there good luck The real reason for a low rating is the customer service I agree with the woman from San Jose who said it was bad unless they know you That was my experience also I took my daughter here and after she left me to go to the bathroom she came back freaked out She said one of the ladies who worked there grabbed her and hugged her upon coming out of the bathroom I m all for being kind to the elderly but my daughter said the woman was creepy and followed her around the store until she found me When we were checking out and having bolts cut the same lady was behind the counter teasing my daughter the lady cutting our fabric seemed to catch on and a very odd conversation about history ensued seriously not what I would consider professional conduct by either of these employees I was proud of my daughter for handling them with kindness but when we left she asked if we could never go there again and we won t when I got home my fabric was cut seriously wonkey Out of the yards we bought none of them were cut remotely straight No thanks to strange old ladies who get their kicks from scaring kids and messing with someone s purchase we ll skip it next time A friend did have a great report going there for seat material and foam for a motorcycle seat on a bike he was restoring so maybe it was just us but low quality fabric our customer service experience means I won t be back unless necessary'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_train.data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b0c5233-2411-4f08-8adc-7a04c41cc424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   133,  4230,   259,    16,  8578,   114,    47,   769,   442,\n",
       "         30625,  2677,   718,  2577,   190, 31179,    16,    10,   117,   213,\n",
       "           655,   274,  7445,  1755,  4230,     8,   425,    16,   372,     8,\n",
       "            65,     9,     5,  2188,     7,   213,   259, 19516,     8,  1632,\n",
       "          8032,    16,    55,  3214,    87, 19632,    50,  4558,  1493,  4682,\n",
       "           239,   253,  2677, 10325,  6464,  3655,    16,  8578,    15, 10199,\n",
       "            13, 30625,     8,    89,   579,    10,  2579,  4230,     9, 22288,\n",
       "         33803,   261, 17796,    53,     5,  1318,     9,   103, 26348,  6771,\n",
       "             5,   614,  7476,   425,  1308,  2979,    16,    14,   209,    32,\n",
       "           295,   417,     8,   910,   417,   847, 26348,    45,   299,  1318,\n",
       "           318,    47,   304,    10, 22939,    50,   213,    13,    10,  1392,\n",
       "            23, 19632,    47,    64,   120,   357,  1318, 10199,    23,   593,\n",
       "             7,     5,   276,   425,  4642,    49, 32791,    32,    59,   786,\n",
       "          5152,   927,    95,   860,     7,   914, 15019,     7, 10199,    89,\n",
       "           205,  6620,    20,   588,  1219,    13,    10,   614,   691,    16,\n",
       "             5,  2111,   544,    38,  2854,    19,     5,   693,    31,   764,\n",
       "          3071,    54,    26,    24,    21,  1099,  3867,    51,   216,    47,\n",
       "           280,    21,   127,   676,    67,    38,   362,   127,  1354,   259,\n",
       "             8,    71,    79,   314,   162,     7,   213,     7,     5,  8080,\n",
       "            79,   376,   124,  7619,  8435,    66,   264,    26,    65,     9,\n",
       "             5, 10717,    54,  1006,    89,  7249,    69,     8, 27425,    69,\n",
       "          2115,   567,    66,     9,     5,  8080,    38,   475,    70,    13,\n",
       "           145,   761,     7,     5,  7497,    53,   127,  1354,    26,     5,\n",
       "           693,    21, 23814,     8,  1432,    69,   198,     5,  1400,   454,\n",
       "            79,   303,   162,   520,    52,    58,  8405,    66,     8,   519,\n",
       "         36668,   847,     5,   276,  6429,    21,   639,     5,  3231, 29752,\n",
       "           127,  1354,     5,  6429,  3931,    84, 10199,  2551,     7,  2916,\n",
       "            15,     8,    10,   182,  8372,  1607,    59,   750, 25825,  3640,\n",
       "            45,    99,    38,    74,  1701,  2038,  2883,    30,  1169,     9,\n",
       "           209,  1321,    38,    21,  2602,     9,   127,  1354,    13,  5516,\n",
       "           106,    19, 15963,    53,    77,    52,   314,    79,   553,   114,\n",
       "            52,   115,   393,   213,    89,   456,     8,    52,   351,   326,\n",
       "            77,    38,   300,   184,   127, 10199,    21,   847,  3640,   351,\n",
       "          5282,  2548,     9,     5,  1314,    52,  2162,  4146,     9,   106,\n",
       "            58,   847, 18684,  1359,   440,  2446,     7,  7782,   793, 10717,\n",
       "            54,   120,    49,  9090,    31,  2850,  5867,  1159,     8, 35204,\n",
       "            19,   951,   579,  2229,    52, 19385, 14514,    24,   220,    86,\n",
       "            83,  1441,   222,    33,    10,   372,   266,   164,    89,    13,\n",
       "          2418,  1468,     8, 21699,    13,    10, 10218,  2418,    15,    10,\n",
       "          4806,    37,    21, 17361,    98,  2085,    24,    21,    95,   201,\n",
       "            53,   614,  1318, 10199,    84,  2111,   544,   676,   839,    38,\n",
       "           351,   326,    28,   124,  3867,  2139,     2,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([1., 0.])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6feda-4d33-4db2-8f9e-37acda9a6373",
   "metadata": {},
   "source": [
    "### Unhelpful Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3109bfb7-b4c2-4ec7-9252-9ff7320f8c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was out in St Louis on a business trip and was looking forward to trying Pappy s due to all the hype from yelp and the travel channel I ordered a full rack of ribs with deep fried corn and green beans The deep fried corn was awesome but I was pretty dissapointed in the ribs I m not sure if it was because I came later in the day around pm shouldn t matter but my ribs were pretty dry I ve had my fair share of dry rub ribs and expect them to still be tender and moist My travel partners were also not too impressed with the ribs from Pappy s Maybe it was an off day for them but this is definitely not close to the best ribs that I ve had'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_val.data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "276225ba-deaa-4dbe-af4f-db1201ac34ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   100,    21,    66,    11,   312,  3217,    15,    10,   265,\n",
       "          1805,     8,    21,   546,   556,     7,   667,   221, 31953,   579,\n",
       "           528,     7,    70,     5, 14761,    31,  1423,   523,   642,     8,\n",
       "             5,  1504,  4238,    38,  2740,    10,   455, 20004,     9, 21443,\n",
       "            19,  1844, 16708,  7636,     8,  2272, 13095,    20,  1844, 16708,\n",
       "          7636,    21,  6344,    53,    38,    21,  1256, 14863,  1115, 26427,\n",
       "            11,     5, 21443,    38,   475,    45,   686,   114,    24,    21,\n",
       "           142,    38,   376,   423,    11,     5,   183,   198,  4751,  4395,\n",
       "           326,   948,    53,   127, 21443,    58,  1256,  3841,    38,  5030,\n",
       "            56,   127,  2105,   458,     9,  3841, 14204, 21443,     8,  1057,\n",
       "           106,     7,   202,    28,  8780,     8, 34257,  1308,  1504,  2567,\n",
       "            58,    67,    45,   350,  6889,    19,     5, 21443,    31,   221,\n",
       "         31953,   579,  5359,    24,    21,    41,   160,   183,    13,   106,\n",
       "            53,    42,    16,  2299,    45,   593,     7,     5,   275, 21443,\n",
       "            14,    38,  5030,    56,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 1.])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_val.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a7e49-10a3-49cf-9733-7a19e6fba1ba",
   "metadata": {},
   "source": [
    "# 2. Data Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f4f47-a59d-4dfb-aab8-04942e3f06aa",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ee3727-336c-4e28-8755-d4b6c4752f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2cd81-1f90-47ca-a6eb-f3f8bd9186fe",
   "metadata": {},
   "source": [
    "## Creating PyTorch Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad4f03c3-a698-4b1a-ac8b-cd36c2c92808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Data_Model(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, attributes, batch_size, max_token_length, model_name):\n",
    "        super().__init__()\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.train_dataset = Helpfulness_Dataset(train_df, tokenizer, attributes, 512)\n",
    "            self.val_dataset = Helpfulness_Dataset(test_df, tokenizer, attributes, 512)\n",
    "        if stage == \"predict\":\n",
    "            self.val_dataset = Helpfulness_Dataset(test_df, tokenizer, attributes, 512)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984497c6-c038-42d8-ae4c-4ee0d2fa1fec",
   "metadata": {},
   "source": [
    "## Create Instance Of Our Data Module And Set It Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48a96c0c-ed66-4601-a0f1-bbab98f60659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\"helpful\", \"unhelpful\"]\n",
    "model_name = \"roberta-base\"\n",
    "batch_size = 8\n",
    "max_token_length = 512\n",
    "hfs_data_module = Helpfulness_Data_Model(attributes, batch_size, max_token_length, model_name)\n",
    "hfs_data_module.setup()\n",
    "dl = hfs_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f22d8d-ef56-4dd4-8ea0-18f8a2ebe2f1",
   "metadata": {},
   "source": [
    "## Number Of Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a391c37e-2568-4ffb-a6fd-7980ab9f105a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de981efd-d13d-485f-a31f-f6ae2e240d11",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db3f67-c0c0-4f33-9522-6d0140f445b8",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e5c7617-9248-4ed5-8782-545359246f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 20:33:16.662555: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 20:33:16.690421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 20:33:17.274545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a0c65-da76-4f3d-9c31-83034f18309e",
   "metadata": {},
   "source": [
    "## Helpfulness Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57b2fc45-c56b-4faa-a42c-61845227a5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Classifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(config[\"model_name\"], return_dict=True)\n",
    "        self.hidden= nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "        self.classification = nn.Linear(self.pretrained_model.config.hidden_size, self.config[\"n_labels\"])\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classification.weight)\n",
    "        self.loss_fun = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        logits = self.classification(pooled_output)\n",
    "        loss = 0 \n",
    "        if labels is not None:\n",
    "            loss = self.loss_fun(logits.view(-1, self.config[\"n_labels\"]), labels.view(-1, self.config[\"n_labels\"]))\n",
    "        return loss, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"train loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": logits, \"labels\": batch[\"labels\"]}\n",
    "    \n",
    "    def validations_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"validation loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": logits, \"labels\": batch[\"labels\"]}\n",
    "    \n",
    "    def predict_step(self, batch, batch_index):\n",
    "        _, logits = self(**batch)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config[\"lr\"], weight_decay=self.config[\"w_decay\"])\n",
    "        total_steps = self.config[\"train_size\"] / self.config[\"bs\"]\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cab09f8-f1e0-4127-9b07-8c5cc525a800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"n_labels\": len(attributes),\n",
    "    \"bs\": 8,\n",
    "    \"lr\": 2e-5,\n",
    "    \"warmup\": 0.2,\n",
    "    \"w_decay\": 0.001,\n",
    "    \"train_size\": len(hfs_data_module.train_dataloader()),\n",
    "    \"n_epochs\": 4\n",
    "}\n",
    "\n",
    "model = Helpfulness_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c52b577-c722-42d8-b1b7-bdcc1d521726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "input_ids = hfs_ds_train.__getitem__(idx)[\"input_ids\"]\n",
    "am = hfs_ds_train.__getitem__(idx)[\"attention_mask\"]\n",
    "labels = hfs_ds_train.__getitem__(idx)[\"labels\"]\n",
    "\n",
    "loss, output = model(input_ids.unsqueeze(dim=0), am.unsqueeze(dim=0), labels.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef71ea88-54ca-46f5-bf25-781a10789e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8006, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor([[-0.2596,  0.1481]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013059ef-ea95-4313-951f-d7fdd6028766",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c8d1f4b-7df2-4a5e-89c6-ccda54a9e48a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type              | Params\n",
      "-------------------------------------------------------\n",
      "0 | pretrained_model | RobertaModel      | 124 M \n",
      "1 | hidden           | Linear            | 590 K \n",
      "2 | classification   | Linear            | 1.5 K \n",
      "3 | loss_fun         | BCEWithLogitsLoss | 0     \n",
      "4 | dropout          | Dropout           | 0     \n",
      "-------------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.951   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7dffcb99cc4dd5b532b6e23ffb12c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "hfs_data_module = Helpfulness_Data_Model(attributes, config[\"bs\"], max_token_length, model_name)\n",
    "hfs_data_module.setup()\n",
    "\n",
    "model = Helpfulness_Classifier(config)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=config[\"n_epochs\"], num_sanity_val_steps=50)\n",
    "trainer.fit(model, hfs_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83acaf-9b2c-4a5c-8304-feed0a33a090",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict / Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85bf163e-c875-4569-8011-11e635dd4d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_reviews(model, dm):\n",
    "    preictions = trainer.predict(model, datamodule=dm)\n",
    "    flattened_prediction = np.stack([torch.sigmoid(torch.Tensor(p)) for batch in preictions for p in batch])\n",
    "    return flattened_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b598e90-7277-4e23-a387-a289b8238aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      helpful  helpful\n",
       "0           0        0\n",
       "1           0        0\n",
       "2           1        1\n",
       "3           1        1\n",
       "4           0        0\n",
       "...       ...      ...\n",
       "1995        0        0\n",
       "1996        1        1\n",
       "1997        1        1\n",
       "1998        0        0\n",
       "1999        1        1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_data_module.val_dataset.data[[\"helpful\", \"helpful\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "958bea8f-4b1e-4599-a810-a6f07f230111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4b1d349d3741898b99db2adf5aa96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_reviews(model, hfs_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98472f99-3394-4458-8781-471a614443cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      helpful  unhelpful\n",
       "0           0          1\n",
       "1           0          1\n",
       "2           1          0\n",
       "3           1          0\n",
       "4           0          1\n",
       "...       ...        ...\n",
       "1995        0          1\n",
       "1996        1          0\n",
       "1997        1          0\n",
       "1998        0          1\n",
       "1999        1          0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpful_array = hfs_data_module.val_dataset.data[[\"helpful\", \"unhelpful\"]]\n",
    "helpful_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d428c5ed-194d-4d34-8c38-d4791befad39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.255624</td>\n",
       "      <td>0.725359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.103792</td>\n",
       "      <td>0.892647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.913614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.193389</td>\n",
       "      <td>0.799366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.331427</td>\n",
       "      <td>0.662039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.091183</td>\n",
       "      <td>0.903223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.257866</td>\n",
       "      <td>0.761975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.436694</td>\n",
       "      <td>0.577040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.170887</td>\n",
       "      <td>0.835405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.564866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     0.255624  0.725359\n",
       "1     0.103792  0.892647\n",
       "2     0.082891  0.913614\n",
       "3     0.193389  0.799366\n",
       "4     0.331427  0.662039\n",
       "...        ...       ...\n",
       "1995  0.091183  0.903223\n",
       "1996  0.257866  0.761975\n",
       "1997  0.436694  0.577040\n",
       "1998  0.170887  0.835405\n",
       "1999  0.425841  0.564866\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41b31b22-2834-4b22-a73e-7b73e11f5de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(predictions, ground_truth_labels):\n",
    "    \n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions.iloc[i][0] > predictions.iloc[i][1]):\n",
    "            helpful = 1\n",
    "            unhelpful = 0\n",
    "        else:\n",
    "            helpful = 0\n",
    "            unhelpful = 1\n",
    "        if helpful == 1 and helpful == ground_truth_labels.iloc[i][\"helpful\"]:\n",
    "            tp += 1 \n",
    "        elif helpful == 1 and helpful != ground_truth_labels.iloc[i][\"helpful\"]:\n",
    "            fp += 1\n",
    "        elif unhelpful == 1 and unhelpful == ground_truth_labels.iloc[i][\"unhelpful\"]:\n",
    "            tn += 1\n",
    "        elif unhelpful == 1 and unhelpful != ground_truth_labels.iloc[i][\"unhelpful\"]:\n",
    "            fn += 1\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a813000d-7819-436a-b66c-ffdba30d3ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive = 531\n",
      "False Positive = 91\n",
      "True negative = 909\n",
      "False negative = 469\n",
      "Total = 2000\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = generate_confusion_matrix(pd.DataFrame(predictions), hfs_data_module.val_dataset.data[[\"helpful\", \"unhelpful\"]])\n",
    "print(f\"True Positive = {tp}\")\n",
    "print(f\"False Positive = {fp}\")\n",
    "print(f\"True negative = {tn}\")\n",
    "print(f\"False negative = {fn}\")\n",
    "print(f\"Total = {tp + fp + tn + fn}\")\n",
    "with open(\"Results/RoBERTa-Base-Met-Clean.txt\", \"w\") as f:\n",
    "    f.write(f\"True Positive = {tp}\\n\")\n",
    "    f.write(f\"False Positive = {fp}\\n\")\n",
    "    f.write(f\"True negative = {tn}\\n\")\n",
    "    f.write(f\"False negative = {fn}\\n\")\n",
    "    f.write(f\"Total = {tp + fp + tn + fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cebe0ca-9073-4503-a062-f1826af920fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(tp, fp, tn, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "    sensitivity = recall  # Sensitivity is another name for Recall\n",
    "    false_positive_rate = fp / (fp + tn) if (fp + tn) != 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, specificity, sensitivity, false_positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9c28dff-37d3-408e-9387-a65f756d756e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.72\n",
      "Precision = 0.8536977491961415\n",
      "Recall = 0.531\n",
      "F1 Score = 0.6547472256473489\n",
      "Specificity = 0.909\n",
      "Sensitivity = 0.531\n",
      "False Positive Rate = 0.091\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score, specificity, sensitivity, false_positive_rate = calculate_metrics(tp, fp, tn, fn)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(f\"Precision = {precision}\")\n",
    "print(f\"Recall = {recall}\")\n",
    "print(f\"F1 Score = {f1_score}\")\n",
    "print(f\"Specificity = {specificity}\")\n",
    "print(f\"Sensitivity = {sensitivity}\")\n",
    "print(f\"False Positive Rate = {false_positive_rate}\")\n",
    "with open(\"Results/RoBERTa-Base-Results-Clean.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy = {accuracy}\\n\")\n",
    "    f.write(f\"Precision = {precision}\\n\")\n",
    "    f.write(f\"Recall = {recall}\\n\")\n",
    "    f.write(f\"F1 Score = {f1_score}\\n\")\n",
    "    f.write(f\"Specificity = {specificity}\\n\")\n",
    "    f.write(f\"Sensitivity = {sensitivity}\\n\")\n",
    "    f.write(f\"False Positive Rate = {false_positive_rate}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
