{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31680e0-9037-40e9-a635-08c2de8ed9a4",
   "metadata": {},
   "source": [
    "# RoBERTa Fine Tunning For Helpfulness Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a039072-ec9b-428f-b95c-84dce51ac2ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347acc6-4841-4897-96ba-01c43a6b2f26",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536151d0-6f17-48be-ada0-cb8b528008a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d879199-46bc-42de-8a44-1b307d49ba5e",
   "metadata": {},
   "source": [
    "## Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94b9715-65b5-43e9-bead-f3818128c473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657855651a6d2c7052a63c2e</td>\n",
       "      <td>The selection here is okay if you're making ga...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a64d48</td>\n",
       "      <td>Now THIS is a restaurant.  Small, tidy, excell...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63de3</td>\n",
       "      <td>In the last five minutes I had two men knock o...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657859921a6d2c7052a6529f</td>\n",
       "      <td>I love Potbelly's.  I've eaten there several t...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657855641a6d2c7052a63332</td>\n",
       "      <td>This is the best thai cuisine around, the curr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7995</td>\n",
       "      <td>657859921a6d2c7052a64d6e</td>\n",
       "      <td>Service was good and friendly.  Food was good ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7996</td>\n",
       "      <td>657855651a6d2c7052a6440c</td>\n",
       "      <td>This place is a complete joke. I bought 4 tire...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7997</td>\n",
       "      <td>657855651a6d2c7052a64353</td>\n",
       "      <td>I waited a week to post my review of White Dog...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7998</td>\n",
       "      <td>657855641a6d2c7052a633cd</td>\n",
       "      <td>We had a Groupon for Euphoria, so my husband a...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>7999</td>\n",
       "      <td>657859931a6d2c7052a659e9</td>\n",
       "      <td>I love this place. It's great for after work h...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657855651a6d2c7052a63c2e   \n",
       "1              1  657859921a6d2c7052a64d48   \n",
       "2              2  657855651a6d2c7052a63de3   \n",
       "3              3  657859921a6d2c7052a6529f   \n",
       "4              4  657855641a6d2c7052a63332   \n",
       "...          ...                       ...   \n",
       "7995        7995  657859921a6d2c7052a64d6e   \n",
       "7996        7996  657855651a6d2c7052a6440c   \n",
       "7997        7997  657855651a6d2c7052a64353   \n",
       "7998        7998  657855641a6d2c7052a633cd   \n",
       "7999        7999  657859931a6d2c7052a659e9   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     The selection here is okay if you're making ga...    helpful        1   \n",
       "1     Now THIS is a restaurant.  Small, tidy, excell...  unhelpful        0   \n",
       "2     In the last five minutes I had two men knock o...    helpful        1   \n",
       "3     I love Potbelly's.  I've eaten there several t...  unhelpful        0   \n",
       "4     This is the best thai cuisine around, the curr...    helpful        1   \n",
       "...                                                 ...        ...      ...   \n",
       "7995  Service was good and friendly.  Food was good ...  unhelpful        0   \n",
       "7996  This place is a complete joke. I bought 4 tire...    helpful        1   \n",
       "7997  I waited a week to post my review of White Dog...    helpful        1   \n",
       "7998  We had a Groupon for Euphoria, so my husband a...    helpful        1   \n",
       "7999  I love this place. It's great for after work h...  unhelpful        0   \n",
       "\n",
       "      unhelpful  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "7995          1  \n",
       "7996          0  \n",
       "7997          0  \n",
       "7998          0  \n",
       "7999          1  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fcfee4-029c-4d24-be29-66a95fe17f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "helpful      4000\n",
       "unhelpful    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d1977e-0da4-4760-af37-68c2e57603a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unhelpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>657859921a6d2c7052a64801</td>\n",
       "      <td>I was out in St. Louis on a business trip and ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>657859921a6d2c7052a647aa</td>\n",
       "      <td>Worst omelet I have ever eaten. With the upcha...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657855651a6d2c7052a63749</td>\n",
       "      <td>I love this place! It is my favorite go to pla...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>657855651a6d2c7052a6408a</td>\n",
       "      <td>Came to Tamarind for lunch on Sunday afternoon...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>657859921a6d2c7052a6554d</td>\n",
       "      <td>Easter Sunday, over crowded at 6:00 PM, staff ...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>657859921a6d2c7052a65259</td>\n",
       "      <td>Love this dealership. Bought my CRV there a fe...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>657855651a6d2c7052a63ce4</td>\n",
       "      <td>We stopped at Tako due to the positive reviews...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>657855651a6d2c7052a63d89</td>\n",
       "      <td>I had a quick get together with a couple of fr...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>657859921a6d2c7052a64b23</td>\n",
       "      <td>After a long week, a girl friend and I decided...</td>\n",
       "      <td>unhelpful</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>657855651a6d2c7052a636bc</td>\n",
       "      <td>So I placed my order boneless wings, she also ...</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                       _id  \\\n",
       "0              0  657859921a6d2c7052a64801   \n",
       "1              1  657859921a6d2c7052a647aa   \n",
       "2              2  657855651a6d2c7052a63749   \n",
       "3              3  657855651a6d2c7052a6408a   \n",
       "4              4  657859921a6d2c7052a6554d   \n",
       "...          ...                       ...   \n",
       "1995        1995  657859921a6d2c7052a65259   \n",
       "1996        1996  657855651a6d2c7052a63ce4   \n",
       "1997        1997  657855651a6d2c7052a63d89   \n",
       "1998        1998  657859921a6d2c7052a64b23   \n",
       "1999        1999  657855651a6d2c7052a636bc   \n",
       "\n",
       "                                                   text      label  helpful  \\\n",
       "0     I was out in St. Louis on a business trip and ...  unhelpful        0   \n",
       "1     Worst omelet I have ever eaten. With the upcha...  unhelpful        0   \n",
       "2     I love this place! It is my favorite go to pla...    helpful        1   \n",
       "3     Came to Tamarind for lunch on Sunday afternoon...    helpful        1   \n",
       "4     Easter Sunday, over crowded at 6:00 PM, staff ...  unhelpful        0   \n",
       "...                                                 ...        ...      ...   \n",
       "1995  Love this dealership. Bought my CRV there a fe...  unhelpful        0   \n",
       "1996  We stopped at Tako due to the positive reviews...    helpful        1   \n",
       "1997  I had a quick get together with a couple of fr...    helpful        1   \n",
       "1998  After a long week, a girl friend and I decided...  unhelpful        0   \n",
       "1999  So I placed my order boneless wings, she also ...    helpful        1   \n",
       "\n",
       "      unhelpful  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1995          1  \n",
       "1996          0  \n",
       "1997          0  \n",
       "1998          1  \n",
       "1999          0  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0c0bff-2328-477e-87a0-71fc29ca48fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "unhelpful    1000\n",
       "helpful      1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b5cd1-d7b0-4a79-a056-0237c48ce6ab",
   "metadata": {},
   "source": [
    "## Build PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b5177a-856a-48ca-9802-ae2218b21b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063075d7-b8a5-4d04-a348-f40106ffffb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, tokenizer, attributes, max_token_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.attributes = attributes\n",
    "        self.max_token_len = max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        text = item.text\n",
    "        attributes = torch.FloatTensor(item[self.attributes])\n",
    "        tokens = self.tokenizer.encode_plus(text,\n",
    "                                            add_special_tokens=True,\n",
    "                                            return_tensors=\"pt\",\n",
    "                                            truncation=True,\n",
    "                                            max_length=self.max_token_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            return_attention_mask=True)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokens.input_ids.flatten(),\n",
    "            \"attention_mask\": tokens.attention_mask.flatten(),\n",
    "            \"labels\": attributes\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82f2cd-b3b0-4e2a-b23f-4cf55ed3ad16",
   "metadata": {},
   "source": [
    "## Create Train And Test PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c1770f-27c2-4ca9-81ac-b223fd2f5d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\"helpful\", \"unhelpful\"]\n",
    "model_name = \"roberta-base\"\n",
    "max_token_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "hfs_ds_train = Helpfulness_Dataset(train_df, tokenizer, attributes, max_token_length)\n",
    "hfs_ds_val = Helpfulness_Dataset(test_df, tokenizer, attributes, max_token_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356846f-49e2-47d8-94d0-cf3b8516f661",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokization Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5b7e4-455b-4be3-8acd-2a77f9f219e8",
   "metadata": {},
   "source": [
    "### Helpful Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8685dd7c-b51d-4512-bd5e-445b6e69b4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The selection here is okay if you're making garments, quilting (even rag) is a no go...ever! Fleece selection and price is great and one of the reasons to go here. Warm and natural batting is more expensive than Hancock or anywhere else except high end quilt shops. Price is okay on fabric for garments and there's a nice selection of silk/rayon/syn but the quality of some fabrics reflects the low everyday price. My opinion is that these are 2nd and 3rd cut fabrics not top quality. If you use a coupon or go for a sale at Hancock you can get better quality fabric at close to the same price. Plus their notions are about non-existant, just try to match thread to fabric there...good luck! \\n\\nThe real reason for a low rating is the customer service! I agree with the woman from San Jose who said it was bad unless they know you. That was my experience also. I took my daughter here and after she left me to go to the bathroom she came back freaked out. She said one of the ladies who worked there grabbed her and hugged her upon coming out of the bathroom. I'm all for being kind to the elderly but my daughter said the woman was creepy and followed her around the store until she found me. When we were checking out and having bolts cut the same lady was behind the counter teasing my daughter, the lady cutting our fabric seemed to catch on and a very odd conversation about history ensued...seriously not what I would consider professional conduct by either of these employees. I was proud of my daughter for handling them with kindness but when we left she asked if we could never go there again, and we won't...when I got home my fabric was cut seriously wonkey. Out of the 8-10 yards we bought none of them were cut remotely straight. No thanks to strange old ladies who get their kicks from scaring kids and messing with someone's purchase, we'll skip it next time! \\n\\nA friend did have a great report going there for seat material and foam for a motorcycle seat on a bike he was restoring...so maybe it was just us but low quality fabric + our customer service experience means I won't be back unless necessary.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_train.data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0c5233-2411-4f08-8adc-7a04c41cc424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   133,  4230,   259,    16,  8578,   114,    47,   214,   442,\n",
       "         30625,     6,  2677,   718,  2577,    36, 12963, 31179,    43,    16,\n",
       "            10,   117,   213,   734,  6294,   328,   274,  7445,  1755,  4230,\n",
       "             8,   425,    16,   372,     8,    65,     9,     5,  2188,     7,\n",
       "           213,   259,     4, 19516,     8,  1632,  8032,    16,    55,  3214,\n",
       "            87, 19632,    50,  4558,  1493,  4682,   239,   253,  2677, 10325,\n",
       "          6464,     4,  3655,    16,  8578,    15, 10199,    13, 30625,     8,\n",
       "            89,    18,    10,  2579,  4230,     9, 22288,    73,  5022,   261,\n",
       "            73, 38972,    53,     5,  1318,     9,   103, 26348,  6771,     5,\n",
       "           614,  7476,   425,     4,  1308,  2979,    16,    14,   209,    32,\n",
       "           132,  1187,     8,   155,  2586,   847, 26348,    45,   299,  1318,\n",
       "             4,   318,    47,   304,    10, 22939,    50,   213,    13,    10,\n",
       "          1392,    23, 19632,    47,    64,   120,   357,  1318, 10199,    23,\n",
       "           593,     7,     5,   276,   425,     4,  4642,    49, 32791,    32,\n",
       "            59,   786,    12,  3463, 33388,     6,    95,   860,     7,   914,\n",
       "         15019,     7, 10199,    89,   734,  8396,  6620,   328,  1437, 50118,\n",
       "         50118,   133,   588,  1219,    13,    10,   614,   691,    16,     5,\n",
       "          2111,   544,   328,    38,  2854,    19,     5,   693,    31,   764,\n",
       "          3071,    54,    26,    24,    21,  1099,  3867,    51,   216,    47,\n",
       "             4,   280,    21,   127,   676,    67,     4,    38,   362,   127,\n",
       "          1354,   259,     8,    71,    79,   314,   162,     7,   213,     7,\n",
       "             5,  8080,    79,   376,   124,  7619,  8435,    66,     4,   264,\n",
       "            26,    65,     9,     5, 10717,    54,  1006,    89,  7249,    69,\n",
       "             8, 27425,    69,  2115,   567,    66,     9,     5,  8080,     4,\n",
       "            38,   437,    70,    13,   145,   761,     7,     5,  7497,    53,\n",
       "           127,  1354,    26,     5,   693,    21, 23814,     8,  1432,    69,\n",
       "           198,     5,  1400,   454,    79,   303,   162,     4,   520,    52,\n",
       "            58,  8405,    66,     8,   519, 36668,   847,     5,   276,  6429,\n",
       "            21,   639,     5,  3231, 29752,   127,  1354,     6,     5,  6429,\n",
       "          3931,    84, 10199,  2551,     7,  2916,    15,     8,    10,   182,\n",
       "          8372,  1607,    59,   750, 25825,   734, 12778,  9997,    45,    99,\n",
       "            38,    74,  1701,  2038,  2883,    30,  1169,     9,   209,  1321,\n",
       "             4,    38,    21,  2602,     9,   127,  1354,    13,  5516,   106,\n",
       "            19, 15963,    53,    77,    52,   314,    79,   553,   114,    52,\n",
       "           115,   393,   213,    89,   456,     6,     8,    52,   351,    75,\n",
       "           734, 14746,    38,   300,   184,   127, 10199,    21,   847,  3640,\n",
       "           351,  5282,     4,  2548,     9,     5,   290,    12,   698,  1314,\n",
       "            52,  2162,  4146,     9,   106,    58,   847, 18684,  1359,     4,\n",
       "           440,  2446,     7,  7782,   793, 10717,    54,   120,    49,  9090,\n",
       "            31,  2850,  5867,  1159,     8, 35204,    19,   951,    18,  2229,\n",
       "             6,    52,   581, 14514,    24,   220,    86,   328,  1437, 50118,\n",
       "         50118,   250,  1441,   222,    33,    10,   372,   266,   164,    89,\n",
       "            13,  2418,  1468,     8, 21699,    13,    10, 10218,  2418,    15,\n",
       "            10,  4806,    37,    21, 17361,   734,  2527,  2085,    24,    21,\n",
       "            95,   201,    53,   614,  1318, 10199,  2055,    84,  2111,   544,\n",
       "           676,   839,    38,   351,    75,    28,   124,  3867,  2139,     4,\n",
       "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([1., 0.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6feda-4d33-4db2-8f9e-37acda9a6373",
   "metadata": {},
   "source": [
    "### Unhelpful Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3109bfb7-b4c2-4ec7-9252-9ff7320f8c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I was out in St. Louis on a business trip and was looking forward to trying Pappy's (due to all the hype from yelp and the travel channel).  I ordered a full rack of ribs with deep fried corn and green beans.  The deep fried corn was awesome but I was pretty dissapointed in the ribs.  I'm not sure if it was because I came later in the day around 6 pm (shouldn't matter) but my ribs were pretty dry.  I've had my fair share of dry rub ribs and expect them to still be tender and moist.  My travel partners were also not too impressed with the ribs from Pappy's.  Maybe it was an off day for them, but this is definitely not close to the best ribs that I've had.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_val.data.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "276225ba-deaa-4dbe-af4f-db1201ac34ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,   100,    21,    66,    11,   312,     4,  3217,    15,    10,\n",
       "           265,  1805,     8,    21,   546,   556,     7,   667,   221, 31953,\n",
       "            18,    36, 17193,     7,    70,     5, 14761,    31,  1423,   523,\n",
       "           642,     8,     5,  1504,  4238,   322,  1437,    38,  2740,    10,\n",
       "           455, 20004,     9, 21443,    19,  1844, 16708,  7636,     8,  2272,\n",
       "         13095,     4,  1437,    20,  1844, 16708,  7636,    21,  6344,    53,\n",
       "            38,    21,  1256, 14863,  1115, 26427,    11,     5, 21443,     4,\n",
       "          1437,    38,   437,    45,   686,   114,    24,    21,   142,    38,\n",
       "           376,   423,    11,     5,   183,   198,   231,  4751,    36, 17276,\n",
       "           282,    75,   948,    43,    53,   127, 21443,    58,  1256,  3841,\n",
       "             4,  1437,    38,   348,    56,   127,  2105,   458,     9,  3841,\n",
       "         14204, 21443,     8,  1057,   106,     7,   202,    28,  8780,     8,\n",
       "         34257,     4,  1437,  1308,  1504,  2567,    58,    67,    45,   350,\n",
       "          6889,    19,     5, 21443,    31,   221, 31953,    18,     4,  1437,\n",
       "          5359,    24,    21,    41,   160,   183,    13,   106,     6,    53,\n",
       "            42,    16,  2299,    45,   593,     7,     5,   275, 21443,    14,\n",
       "            38,   348,    56,     4,     2,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 1.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_ds_val.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a7e49-10a3-49cf-9733-7a19e6fba1ba",
   "metadata": {},
   "source": [
    "# 2. Data Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f4f47-a59d-4dfb-aab8-04942e3f06aa",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ee3727-336c-4e28-8755-d4b6c4752f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2cd81-1f90-47ca-a6eb-f3f8bd9186fe",
   "metadata": {},
   "source": [
    "## Creating PyTorch Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4f03c3-a698-4b1a-ac8b-cd36c2c92808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Data_Model(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, attributes, batch_size, max_token_length, model_name):\n",
    "        super().__init__()\n",
    "        self.attributes = attributes\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.train_dataset = Helpfulness_Dataset(train_df, tokenizer, attributes, 512)\n",
    "            self.val_dataset = Helpfulness_Dataset(test_df, tokenizer, attributes, 512)\n",
    "        if stage == \"predict\":\n",
    "            self.val_dataset = Helpfulness_Dataset(test_df, tokenizer, attributes, 512)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984497c6-c038-42d8-ae4c-4ee0d2fa1fec",
   "metadata": {},
   "source": [
    "## Create Instance Of Our Data Module And Set It Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a96c0c-ed66-4601-a0f1-bbab98f60659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\"helpful\", \"unhelpful\"]\n",
    "model_name = \"roberta-base\"\n",
    "batch_size = 8\n",
    "max_token_length = 512\n",
    "hfs_data_module = Helpfulness_Data_Model(attributes, batch_size, max_token_length, model_name)\n",
    "hfs_data_module.setup()\n",
    "dl = hfs_data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f22d8d-ef56-4dd4-8ea0-18f8a2ebe2f1",
   "metadata": {},
   "source": [
    "## Number Of Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a391c37e-2568-4ffb-a6fd-7980ab9f105a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de981efd-d13d-485f-a31f-f6ae2e240d11",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db3f67-c0c0-4f33-9522-6d0140f445b8",
   "metadata": {},
   "source": [
    "## Import Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e5c7617-9248-4ed5-8782-545359246f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 02:11:07.468049: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-23 02:11:07.496683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-23 02:11:08.106008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchmetrics.functional.classification import auroc\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a0c65-da76-4f3d-9c31-83034f18309e",
   "metadata": {},
   "source": [
    "## Helpfulness Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b2fc45-c56b-4faa-a42c-61845227a5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Helpfulness_Classifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.pretrained_model = AutoModel.from_pretrained(config[\"model_name\"], return_dict=True)\n",
    "        self.hidden= nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
    "        self.classification = nn.Linear(self.pretrained_model.config.hidden_size, self.config[\"n_labels\"])\n",
    "        torch.nn.init.xavier_uniform_(self.hidden.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.classification.weight)\n",
    "        self.loss_fun = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "        self.dropout = nn.Dropout()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.pretrained_model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)\n",
    "        pooled_output = self.hidden(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        pooled_output = F.relu(pooled_output)\n",
    "        logits = self.classification(pooled_output)\n",
    "        loss = 0 \n",
    "        if labels is not None:\n",
    "            loss = self.loss_fun(logits.view(-1, self.config[\"n_labels\"]), labels.view(-1, self.config[\"n_labels\"]))\n",
    "        return loss, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"train loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": logits, \"labels\": batch[\"labels\"]}\n",
    "    \n",
    "    def validations_step(self, batch, batch_index):\n",
    "        loss, logits = self(**batch)\n",
    "        self.log(\"validation loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"val_loss\": loss, \"predictions\": logits, \"labels\": batch[\"labels\"]}\n",
    "    \n",
    "    def predict_step(self, batch, batch_index):\n",
    "        _, logits = self(**batch)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.config[\"lr\"], weight_decay=self.config[\"w_decay\"])\n",
    "        total_steps = self.config[\"train_size\"] / self.config[\"bs\"]\n",
    "        warmup_steps = math.floor(total_steps * self.config[\"warmup\"])\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cab09f8-f1e0-4127-9b07-8c5cc525a800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"n_labels\": len(attributes),\n",
    "    \"bs\": 8,\n",
    "    \"lr\": 2e-5,\n",
    "    \"warmup\": 0.2,\n",
    "    \"w_decay\": 0.001,\n",
    "    \"train_size\": len(hfs_data_module.train_dataloader()),\n",
    "    \"n_epochs\": 4\n",
    "}\n",
    "\n",
    "model = Helpfulness_Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c52b577-c722-42d8-b1b7-bdcc1d521726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "input_ids = hfs_ds_train.__getitem__(idx)[\"input_ids\"]\n",
    "am = hfs_ds_train.__getitem__(idx)[\"attention_mask\"]\n",
    "labels = hfs_ds_train.__getitem__(idx)[\"labels\"]\n",
    "\n",
    "loss, output = model(input_ids.unsqueeze(dim=0), am.unsqueeze(dim=0), labels.unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef71ea88-54ca-46f5-bf25-781a10789e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6558, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor([[-0.4042, -0.7219]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013059ef-ea95-4313-951f-d7fdd6028766",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c8d1f4b-7df2-4a5e-89c6-ccda54a9e48a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type              | Params\n",
      "-------------------------------------------------------\n",
      "0 | pretrained_model | RobertaModel      | 124 M \n",
      "1 | hidden           | Linear            | 590 K \n",
      "2 | classification   | Linear            | 1.5 K \n",
      "3 | loss_fun         | BCEWithLogitsLoss | 0     \n",
      "4 | dropout          | Dropout           | 0     \n",
      "-------------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "500.951   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a1dc42e3f40ef8c21b18e1ed0dee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "hfs_data_module = Helpfulness_Data_Model(attributes, config[\"bs\"], max_token_length, model_name)\n",
    "hfs_data_module.setup()\n",
    "\n",
    "model = Helpfulness_Classifier(config)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=config[\"n_epochs\"], num_sanity_val_steps=50)\n",
    "trainer.fit(model, hfs_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83acaf-9b2c-4a5c-8304-feed0a33a090",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict / Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a58ea5-5cbe-47df-beb4-361bd59c4c5a",
   "metadata": {},
   "source": [
    "### Import Neded Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bf163e-c875-4569-8011-11e635dd4d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_reviews(model, dm):\n",
    "    preictions = trainer.predict(model, datamodule=dm)\n",
    "    flattened_prediction = np.stack([torch.sigmoid(torch.Tensor(p)) for batch in preictions for p in batch])\n",
    "    return flattened_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b598e90-7277-4e23-a387-a289b8238aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      helpful  helpful\n",
       "0           0        0\n",
       "1           0        0\n",
       "2           1        1\n",
       "3           1        1\n",
       "4           0        0\n",
       "...       ...      ...\n",
       "1995        0        0\n",
       "1996        1        1\n",
       "1997        1        1\n",
       "1998        0        0\n",
       "1999        1        1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfs_data_module.val_dataset.data[[\"helpful\", \"helpful\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "958bea8f-4b1e-4599-a810-a6f07f230111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cf3ba689f645e18bc1a0d612110f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "predictions = classify_reviews(model, hfs_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d428c5ed-194d-4d34-8c38-d4791befad39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286865</td>\n",
       "      <td>0.735822</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133672</td>\n",
       "      <td>0.852289</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125041</td>\n",
       "      <td>0.895952</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397454</td>\n",
       "      <td>0.658083</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.777611</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.071292</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.761461</td>\n",
       "      <td>0.288247</td>\n",
       "      <td>helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.279996</td>\n",
       "      <td>0.680565</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.399423</td>\n",
       "      <td>0.625241</td>\n",
       "      <td>unhelpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1      label\n",
       "0     0.286865  0.735822  unhelpful\n",
       "1     0.133672  0.852289  unhelpful\n",
       "2     0.125041  0.895952  unhelpful\n",
       "3     0.397454  0.658083  unhelpful\n",
       "4     0.222300  0.777611  unhelpful\n",
       "...        ...       ...        ...\n",
       "1995  0.071292  0.898162  unhelpful\n",
       "1996  0.277308  0.727969  unhelpful\n",
       "1997  0.761461  0.288247    helpful\n",
       "1998  0.279996  0.680565  unhelpful\n",
       "1999  0.399423  0.625241  unhelpful\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df[\"label\"] = \"unhelpful\"\n",
    "predictions_df.loc[predictions_df[0] > 0.5, 'label'] = 'helpful'\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8334078-425b-404b-84fb-4e0d1d1ffe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "unhelpful    1157\n",
       "helpful       843\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41b31b22-2834-4b22-a73e-7b73e11f5de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(predictions, ground_truth_labels):\n",
    "    \n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        if ground_truth_labels.iloc[i][\"label\"] == \"helpful\":\n",
    "            if predictions.iloc[i][\"label\"] == \"helpful\":\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp +=1\n",
    "        else:\n",
    "            if predictions.iloc[i][\"label\"] == \"unhelpful\":\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn +=1\n",
    "            \n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6196ef20-a899-4e29-8a3f-6b34073ccf80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive = 694\n",
      "False Positive = 306\n",
      "True negative = 851\n",
      "False negative = 149\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = generate_confusion_matrix(predictions_df,  hfs_data_module.val_dataset.data)\n",
    "\n",
    "print(f\"True Positive = {tp}\")\n",
    "print(f\"False Positive = {fp}\")\n",
    "print(f\"True negative = {tn}\")\n",
    "print(f\"False negative = {fn}\")\n",
    "\n",
    "with open(\"Results/RoBERTa-Base-Met.txt\", \"w\") as f:\n",
    "    f.write(f\"True Positive = {tp}\\n\")\n",
    "    f.write(f\"False Positive = {fp}\\n\")\n",
    "    f.write(f\"True negative = {tn}\\n\")\n",
    "    f.write(f\"False negative = {fn}\\n\")\n",
    "    f.write(f\"Total = {tp + fp + tn + fn }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddb20d5b-c897-4907-88d3-7d9966fd96e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_results(tp, fp, tn, fn):\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) != 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0.0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c711bc7-8a48-4517-b539-9289fe2135b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7725\n",
      "Precision = 0.694\n",
      "Recall = 0.8232502965599051\n",
      "F1 Score = 0.7531199131850244\n",
      "Specificity = 0.7355229040622299\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1_score, specificity = gen_results(tp, fp, tn, fn)\n",
    "\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(f\"Precision = {precision}\")\n",
    "print(f\"Recall = {recall}\")\n",
    "print(f\"F1 Score = {f1_score}\")\n",
    "print(f\"Specificity = {specificity}\")\n",
    "\n",
    "with open(\"Results/RoBERTa-Base-Results.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy = {accuracy}\\n\")\n",
    "    f.write(f\"Precision = {precision}\\n\")\n",
    "    f.write(f\"Recall = {recall}\\n\")\n",
    "    f.write(f\"F1 Score = {f1_score}\\n\")\n",
    "    f.write(f\"Specificity = {specificity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
